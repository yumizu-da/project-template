services:
  cpu:
    container_name: ml-project-template.cpu
    build:
      context: .
      dockerfile: docker/Dockerfile.cpu
    shm_size: '16gb'
    volumes:
      - type: bind
        source: $PWD
        target: /workspace
      - type: volume
        source: venv
        target: /workspace/.venv
    working_dir: /workspace
    tty: true
  cuda:
    container_name: ml-project-template.cuda
    build:
      context: .
      dockerfile: docker/Dockerfile.cuda
    shm_size: '64gb'
    volumes:
      - type: bind
        source: $PWD
        target: /workspace
      - type: volume
        source: venv
        target: /workspace/.venv
    working_dir: /workspace
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    tty: true

volumes:
  venv:
